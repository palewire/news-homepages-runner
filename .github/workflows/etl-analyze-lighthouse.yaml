name: "Scheduled ETL: Analyze Lighthouse"

on:
  # schedule:
  #   - cron: '0 10 * * *'
  workflow_dispatch:

concurrency:
  group: analyze-lighthouse
  cancel-in-progress: true

jobs:
  lighthouse:
    name: Audits
    runs-on: ubuntu-latest
    timeout-minutes: 60
    continue-on-error: true
    steps:
      - id: checkout
        name: Checkout
        uses: actions/checkout@v3

      - id: install
        name: Install
        uses: ./.github/actions/install

      - id: analyze
        name: Analyze Lighthouse audits
        run: pipenv run newshomepages-analyze lighthouse -o ./
        shell: bash

      - id: save
        name: Save artifact
        uses: actions/upload-artifact@v3
        with:
          name: extracts
          path: ./lighthouse-analysis.csv
          if-no-files-found: error

      - id: upload-to-internet-archive
        name: Upload files to archive.org
        uses: palewire/internet-archive-upload@v1
        with:
          access-key: ${{ secrets.IA_ACCESS_KEY }}
          secret-key: ${{ secrets.IA_SECRET_KEY }}
          identifier: news-homepages-extracts
          files: lighthouse-analysis.csv
