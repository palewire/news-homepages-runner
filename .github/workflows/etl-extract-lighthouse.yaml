name: "Scheduled ETL: Extract Lighthouse sample"

on:
  schedule:
    - cron: '30 0 * * *'
  workflow_dispatch:

concurrency:
  group: extract-lighthouse
  cancel-in-progress: true

jobs:
  download-lighthouse:
    name: Download Lighthouse
    runs-on: ubuntu-latest
    steps:
      - id: checkout
        name: Checkout
        uses: actions/checkout@v3

      - id: install
        name: Install
        uses: ./.github/actions/install

      - id: cache
        name: Update cache
        uses: actions/cache@v3
        with:
          path: ~/.cache
          key: extract-lighthouse-${{ github.run_id }}
          restore-keys: |
            extract-lighthouse

      - id: download-lighthouse
        name: Download Lighthouse files
        run: pipenv run newshomepages-extract lighthouse --days=7 --output-path=./lighthouse-sample.csv;
        shell: bash

      - id: upload-to-internet-archive
        name: Upload files to archive.org
        uses: palewire/internet-archive-upload@v1
        with:
          access-key: ${{ secrets.IA_ACCESS_KEY }}
          secret-key: ${{ secrets.IA_SECRET_KEY }}
          identifier: news-homepages-extracts
          files: lighthouse-sample.csv
